# This is the detailed example config if you want to make custom configurations
# Will add example for advanced configuration

run:
  categories: ["cs.AI", "cs.CV", "cs.RO", "cs.SY", "astro-ph.EP", "math.OC", "physics.space-ph"]
  send_log: true
  log_dir: ./logs

fetch:
  days: 8
  max_results: 768
  max_retries: 10

summarize:
  provider: deepseek
  api_key: env:DEEPSEEK_API_KEY
  base_url: https://api.deepseek.com/v1
  model: deepseek-reasoner
  batch: true
  system_prompt: file:./prompts/summ_lm/system.md
  user_prompt_template: file:./prompts/summ_lm/user.md
  completion_options:
    temperature: 0.6
  context_length: 65536

rate:
  strategy: hybrid
  top_k: 200
  max_selected: 10
  embedder:
    provider: siliconflow
    api_key: env:SILICONFLOW_API_KEY
    base_url: https://api.siliconflow.cn/v1
    model: Qwen/Qwen3-Embedding-0.6B
    batch: false
    query_template: file:./prompts/rate_emb/query.md
    user_interests: "AI, machine learning, astronomy and astronautics"
    context_length: 32768
  llm:
    provider: deepseek
    api_key: env:DEEPSEEK_API_KEY
    base_url: https://api.deepseek.com/v1
    model: deepseek-chat
    batch: true
    system_prompt: "You are an expert research paper evaluator"
    user_prompt_template: file:prompts/rate_lm/user.md
    completion_options:
      temperature: 0.2
      max_tokens: 1024
    context_length: 65536
    criteria:
      novelty:
        description: "How original and innovative are the contributions?"
        weight: 0.3
      methodology:
        description: "How rigorous is the experimental design and evaluation?"
        weight: 0.25
      clarity:
        description: "How well-written and understandable is the paper?"
        weight: 0.2
      impact:
        description: "How significant are the potential applications and impact?"
        weight: 0.15
      relevance:
        description: "How well does this paper match the user's research interests of AI, machine learning and astronomy?"
        weight: 0.1
  
parse:
  enable_vlm: true
  tmp_dir: ./tmp
  fast_parser_timeout_seconds: 300
  vlm:
    provider: modelscope
    api_key: env:SILICONFLOW_API_KEY
    base_url: https://api.siliconflow.cn/v1
    model: Qwen/Qwen2.5-VL-32B-Instruct
    batch: false
    system_prompt: file:prompts/parse_vlm/system.md
    user_prompt: file:prompts/parse_vlm/user.md
    completion_options:
      temperature: 0.2
    dpi: 200

batch:
  tmp_dir: ./tmp
  max_wait_hours: 24
  poll_interval_seconds: 30
  fallback_on_error: true

cache:
  dir: ~/.cache/arxiv-autosumm
  ttl_days: 14

render:
  formats: ["pdf"]
  output_dir: ./output
  base_filename: null
  md:
    include_pagebreaks: true
  pdf:
    pdf_engine: xelatex
    highlight_style: pygments
    font_size: 14pt
    document_class: extarticle
    margin: 1.0in
    colorlinks: true
    link_color: RoyalBlue
    line_stretch: 1.10
    pandoc_input_format: "markdown+raw_tex+yaml_metadata_block"
    pandoc_from_format: gfm
    list_item_sep: 0pt
    list_par_sep: 0pt
    list_top_sep: 6pt
  html:
    math_renderer: mathjax
    mathjax_url: null
    katex_url: null
    include_toc: true
    toc_depth: 3
    number_sections: false
    standalone: true
    self_contained: false
    css_file: null
    css_inline: null
    template_file: null
    highlight_style: pygments
    html5: true
  azw3:
    calibre_path: /usr/bin/calibre
    author: "ArXiv AutoSumm"
    language: enable_vlm
    description: null
    cover_image: null
    

deliver:
  smtp_server: smtp.163.com
  port: 465
  sender: arxiv_bot@163.com
  recipient: kaupane20@yeah.net
  password: env:SMTP_PASSWORD
    